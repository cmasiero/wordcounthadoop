Per indicare al job quali sono i formati dell’input e dell’output sono disponibili i metodi setInputFormatClass() e setOutputFormatClass(); dato che il formato dell’oggetto di input è di testo, possiamo utilizzare l’oggetto TextInputFormat. Utilizziamo poi l’oggetto TextOutputFormat per impostare il formato dell’output.

TextInputFormat e TextOutputFormat estendono rispettivamente FileInputFormat e FileOutputFormat che, a loro volta, estendono InputFormat e OutputFormat. Questi ultimi permettono di specificare il formato accettato in fase di input e quello da fornire in output, inoltre, permettono di effettuare un ragionamento sul numero di funzioni map/reduce in cui partizionare il job. Dimensionare opportunamente il job può radicalmente cambiare le prestazioni dell’elaborazione.

Quante funzioni map/reduce per un job? Come impostare il numero di map e di reduce? La scelta del numero di map dipende dal numero di blocchi DFS dell’input. La documentazione indica in 10-100map/node il valore per raggiungere il giusto livello di parallelismo. Per quanto riguarda il legame tra il numero di map e l’InputFormat, invece, di default la dimensione del blocco DFS viene considerata come un limite superiore in cui suddividere i dati di ingresso per le funzioni map. Ad esempio, se i dati di input sono 10TB, con blocchi DFS da 128MB, verranno automaticamente create 82.000 funzioni map. In alternativa, lo sviluppatore può specificare nel codice il numero di map da creare attraverso il metodo conf.setNumMapTasks(int num). In maniera analoga, possiamo impostare il numero di reduce tramite conf.setNumReduceTasks(int num).

Attraverso i metodi setOutputKeyClass() e setOutputValueClass() possiamo specificare rispettivamente il tipo di oggetto per la KeyOUT e il ValueOUT. Con i metodi setMapperClass() e setReduceClass() possiamo invece indicare al job le funzioni map e reduce. Infine, il framework fornisce gli oggetti FileInputFormat e FileOutputFormat per comunicare al job le directory di input e di output. Nel secondo caso possiamo notare l’utilizzo di setOutputPath() per comunicare al job dove scrivere un unico output, mentre per il primo caso possiamo utilizzare un metodo per aggiungere una o più sorgenti di input, per tale motivo quindi viene predisposto il metodo addInputPath().
